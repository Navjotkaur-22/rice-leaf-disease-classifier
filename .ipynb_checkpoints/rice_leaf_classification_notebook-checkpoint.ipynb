{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de5c11fa",
   "metadata": {},
   "source": [
    "\n",
    "# Rice Leaf Disease Classification — Ready-to-Run Notebook\n",
    "**Purpose:** End-to-end local Jupyter notebook for EDA, training a CNN, augmentation experiments, and model comparison — prepared for GitHub upload.\n",
    "\n",
    "**Files used (from your upload):**\n",
    "- Dataset ZIP: `/mnt/data/riceleafdataset.zip`\n",
    "- Project brief: `/mnt/data/PRCP-1001-RiceLeaf.docx`  \n",
    "(These local paths are already present in this environment.)\n",
    "\n",
    "**Instructions:**  \n",
    "1. Run all cells sequentially.  \n",
    "2. If you want to train faster, reduce `EPOCHS` or use a GPU runtime.  \n",
    "3. Transfer-learning section will try to load ImageNet weights; if internet is unavailable it falls back to training without pretrained weights (the code handles that gracefully).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c7fa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Imports and unzip dataset\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_ZIP = \"/mnt/data/riceleafdataset.zip\"   # <--- dataset zip uploaded by you\n",
    "EXTRACT_TO = \"/mnt/data/riceleafdataset\"\n",
    "\n",
    "os.makedirs(EXTRACT_TO, exist_ok=True)\n",
    "\n",
    "if os.path.exists(DATA_ZIP):\n",
    "    with zipfile.ZipFile(DATA_ZIP, 'r') as z:\n",
    "        z.extractall(EXTRACT_TO)\n",
    "    print(\"Extracted to:\", EXTRACT_TO)\n",
    "else:\n",
    "    print(\"Dataset zip not found at:\", DATA_ZIP)\n",
    "\n",
    "# show folder structure (first two levels)\n",
    "for root, dirs, files in os.walk(EXTRACT_TO):\n",
    "    level = root.replace(EXTRACT_TO, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{Path(root).name}/\")\n",
    "    if level < 2:\n",
    "        for f in files[:5]:\n",
    "            print(f\"{indent}  - {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3441b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Basic EDA - class counts, sample images, image sizes\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Try to detect image folder inside the extracted directory\n",
    "def find_image_folder(base):\n",
    "    for root, dirs, files in os.walk(base):\n",
    "        imgs = [f for f in files if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
    "        if imgs:\n",
    "            return root\n",
    "    return None\n",
    "\n",
    "IMG_FOLDER = find_image_folder(\"/mnt/data/riceleafdataset\")\n",
    "print(\"Image folder detected:\", IMG_FOLDER)\n",
    "\n",
    "from collections import defaultdict\n",
    "class_counts = defaultdict(int)\n",
    "samples = defaultdict(list)\n",
    "if IMG_FOLDER:\n",
    "    for root, dirs, files in os.walk(IMG_FOLDER):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(('.jpg','.jpeg','.png')):\n",
    "                cls = Path(root).name\n",
    "                class_counts[cls] += 1\n",
    "                if len(samples[cls]) < 5:\n",
    "                    samples[cls].append(os.path.join(root,f))\n",
    "\n",
    "print(\"Class counts:\")\n",
    "for k,v in class_counts.items():\n",
    "    print(f\" - {k}: {v}\")\n",
    "\n",
    "# class distribution plot\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(list(class_counts.keys()), list(class_counts.values()))\n",
    "plt.title(\"Class distribution\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# sample images\n",
    "plt.figure(figsize=(10,4))\n",
    "i = 1\n",
    "for cls, imgs in samples.items():\n",
    "    if imgs:\n",
    "        img = Image.open(imgs[0])\n",
    "        plt.subplot(1, len(samples), i)\n",
    "        plt.imshow(img)\n",
    "        plt.title(cls)\n",
    "        plt.axis('off')\n",
    "        i += 1\n",
    "plt.show()\n",
    "\n",
    "# image size stats\n",
    "sizes = []\n",
    "for root, dirs, files in os.walk(IMG_FOLDER):\n",
    "    for f in files:\n",
    "        if f.lower().endswith(('.jpg','.jpeg','.png')):\n",
    "            try:\n",
    "                w,h = Image.open(os.path.join(root,f)).size\n",
    "                sizes.append((w,h))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "if sizes:\n",
    "    sizes_arr = np.array(sizes)\n",
    "    print(\"Image size stats (w x h):\")\n",
    "    print(\" - min:\", sizes_arr.min(axis=0))\n",
    "    print(\" - max:\", sizes_arr.max(axis=0))\n",
    "    print(\" - median:\", np.median(sizes_arr, axis=0))\n",
    "else:\n",
    "    print(\"No image sizes found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb525c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Prepare Keras ImageDataGenerators (train/val split) and utility functions\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "IMG_SIZE = (224,224)\n",
    "BATCH_SIZE = 8\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# build file list and labels\n",
    "filepaths = []\n",
    "labels = []\n",
    "for root, dirs, files in os.walk(IMG_FOLDER):\n",
    "    for f in files:\n",
    "        if f.lower().endswith(('.jpg','.jpeg','.png')):\n",
    "            filepaths.append(os.path.join(root,f))\n",
    "            labels.append(Path(root).name)\n",
    "\n",
    "print(\"Total images found:\", len(filepaths))\n",
    "\n",
    "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
    "    filepaths, labels, test_size=0.2, stratify=labels, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_aug_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.15,\n",
    "    brightness_range=(0.7,1.3),\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "def paths_to_generator(paths, labels, datagen, shuffle=True):\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame({\"filename\": paths, \"class\": labels})\n",
    "    gen = datagen.flow_from_dataframe(\n",
    "        df,\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"class\",\n",
    "        target_size=IMG_SIZE,\n",
    "        class_mode=\"categorical\",\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=shuffle\n",
    "    )\n",
    "    return gen\n",
    "\n",
    "train_gen = paths_to_generator(train_paths, train_labels, train_datagen)\n",
    "train_aug_gen = paths_to_generator(train_paths, train_labels, train_aug_datagen)\n",
    "val_gen = paths_to_generator(val_paths, val_labels, val_datagen, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6834fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Define a simple CNN model (baseline)\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_simple_cnn(input_shape=IMG_SIZE + (3,), num_classes=None):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3,3), activation='relu')(inputs)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(64, (3,3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Conv2D(128, (3,3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "num_classes = train_gen.num_classes\n",
    "model_baseline = build_simple_cnn(num_classes=num_classes)\n",
    "model_baseline.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_baseline.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88784a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Train baseline model (small epochs for quick testing)\n",
    "EPOCHS = 8\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "]\n",
    "history_baseline = model_baseline.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "# plot accuracy and loss\n",
    "plt.figure()\n",
    "plt.plot(history_baseline.history['accuracy'], label='train_acc')\n",
    "plt.plot(history_baseline.history['val_accuracy'], label='val_acc')\n",
    "plt.title('Baseline Model Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_baseline.history['loss'], label='train_loss')\n",
    "plt.plot(history_baseline.history['val_loss'], label='val_loss')\n",
    "plt.title('Baseline Model Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78422d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6) Train model with data augmentation (same architecture)\n",
    "model_aug = build_simple_cnn(num_classes=num_classes)\n",
    "model_aug.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "EPOCHS = 12\n",
    "history_aug = model_aug.fit(\n",
    "    train_aug_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_aug.history['accuracy'], label='train_acc_aug')\n",
    "plt.plot(history_aug.history['val_accuracy'], label='val_acc_aug')\n",
    "plt.title('Augmented Model Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_aug.history['loss'], label='train_loss_aug')\n",
    "plt.plot(history_aug.history['val_loss'], label='val_loss_aug')\n",
    "plt.title('Augmented Model Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afae396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7) Confusion matrix + classification report for best model (choose augmented model for example)\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "best_model = model_aug\n",
    "\n",
    "val_steps = int(np.ceil(val_gen.samples / val_gen.batch_size))\n",
    "preds = best_model.predict(val_gen, steps=val_steps)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "y_true = val_gen.classes\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.xticks(range(len(val_gen.class_indices)), list(val_gen.class_indices.keys()), rotation=45)\n",
    "plt.yticks(range(len(val_gen.class_indices)), list(val_gen.class_indices.keys()))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=list(val_gen.class_indices.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba06bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 8) Transfer Learning (MobileNetV2) - try to use pretrained weights; fallback if not available\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "def build_mobilenetv2(num_classes, input_shape=IMG_SIZE+(3,), weights='imagenet'):\n",
    "    base = MobileNetV2(include_top=False, input_shape=input_shape, weights=weights)\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base.input, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "try:\n",
    "    model_tl = build_mobilenetv2(num_classes=num_classes, weights='imagenet')\n",
    "    print('Loaded MobileNetV2 with ImageNet weights.')\n",
    "except Exception as e:\n",
    "    print('Could not load pretrained weights (likely offline). Falling back to uninitialized MobileNetV2. Error:', e)\n",
    "    model_tl = build_mobilenetv2(num_classes=num_classes, weights=None)\n",
    "\n",
    "model_tl.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_tl.summary()\n",
    "\n",
    "EPOCHS = 8\n",
    "history_tl = model_tl.fit(\n",
    "    train_aug_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history_tl.history['accuracy'], label='train_acc_tl')\n",
    "plt.plot(history_tl.history['val_accuracy'], label='val_acc_tl')\n",
    "plt.title('Transfer Learning Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4982dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 9) Save the best model and label map\n",
    "MODEL_OUT = \"/mnt/data/rice_leaf_best_model.h5\"\n",
    "best_model.save(MODEL_OUT)\n",
    "print(\"Saved model to:\", MODEL_OUT)\n",
    "\n",
    "import json\n",
    "labels_map = {v: k for k, v in val_gen.class_indices.items()}\n",
    "with open(\"/mnt/data/label_map.json\", \"w\") as f:\n",
    "    json.dump(labels_map, f)\n",
    "print(\"Saved label map to /mnt/data/label_map.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa7babb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 10) Prediction helper: load model and predict on a new image\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def predict_image(img_path, model_path=MODEL_OUT, label_map_path=\"/mnt/data/label_map.json\"):\n",
    "    model = load_model(model_path)\n",
    "    import json\n",
    "    with open(label_map_path, \"r\") as f:\n",
    "        label_map = json.load(f)\n",
    "    img = Image.open(img_path).convert('RGB').resize(IMG_SIZE)\n",
    "    arr = np.array(img)/255.0\n",
    "    arr = np.expand_dims(arr, 0)\n",
    "    preds = model.predict(arr)\n",
    "    cls = np.argmax(preds, axis=1)[0]\n",
    "    return label_map[str(cls)], float(np.max(preds))\n",
    "\n",
    "# Example usage (uncomment and provide path):\n",
    "# print(predict_image(\"/path/to/some_leaf.jpg\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d32fb56",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Notes & Next Steps (for GitHub upload)\n",
    "- Notebook saved as this single `.ipynb` file — suitable for local Jupyter and for pushing to GitHub.\n",
    "- If you want to run faster, use a GPU runtime (Colab / local GPU). Reduce BATCH_SIZE or IMG_SIZE for quick tests.\n",
    "- Transfer-learning with ImageNet weights needs internet. The code falls back if offline.\n",
    "- I recommend adding a small `requirements.txt` when uploading to GitHub with pinned versions:\n",
    "```\n",
    "tensorflow\n",
    "numpy\n",
    "pandas\n",
    "matplotlib\n",
    "scikit-learn\n",
    "Pillow\n",
    "```\n",
    "- If you want, I can also generate a ready `README.md` and `requirements.txt` and push all files into a ZIP for upload.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
